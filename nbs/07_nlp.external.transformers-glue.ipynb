{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "# hide\n",
    "import sys\n",
    "if 'google.colab' in sys.modules: \n",
    "    !pip install -Uqq fastai transformers datasets\n",
    "    !pip install -q git+git://github.com/walkwithfastai/walkwithfastai.github.io.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#all_slow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "# Text classification with transformers (intermediate)\n",
    "\n",
    "> Fine-tuning pre-trained LM from HuggingFace model hub on GLUE benchmark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#hide\n",
    "from wwf.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "from fastai.text.all import *\n",
    "\n",
    "from datasets import load_dataset, concatenate_datasets\n",
    "from inspect import signature\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "---\n",
       "This article is also a Jupyter Notebook available to be run from the top down. There\n",
       "will be code snippets that you can then run in any environment.\n",
       "\n",
       "Below are the versions of `fastai`, `fastcore`, `transformers`, and `datasets` currently running at the time of writing this:\n",
       "* `fastai` : 2.3.1 \n",
       "* `fastcore` : 1.3.19 \n",
       "* `transformers` : 4.6.0 \n",
       "* `datasets` : 1.6.1 \n",
       "---"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#hide_input\n",
    "state_versions(['fastai', 'fastcore', 'transformers', 'datasets'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Setup\n",
    "\n",
    "In this notebook we will look at how to conbine the power of [HuggingFace](https://huggingface.co/) with great flexibility of [fastai](https://www.fast.ai/). For this purpose we will be finetuning `distilroberta-base` on The [General Language Understanding Evaluation(GLUE) benchmark](https://gluebenchmark.com/) tasks.\n",
    "\n",
    "To give you a grasp on what are we dealing with, here is a brief summary of GLUE tasks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Task description</th>\n",
       "      <th>Size</th>\n",
       "      <th>Metrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cola</th>\n",
       "      <td>Corpus of Linguistic Acceptability</td>\n",
       "      <td>Determine whether it is a grammatical sentence</td>\n",
       "      <td>8.5k</td>\n",
       "      <td>matthews_corrcoef</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sst2</th>\n",
       "      <td>Stanford Sentiment Treebank</td>\n",
       "      <td>Predict the sentiment of a givensentence</td>\n",
       "      <td>67k</td>\n",
       "      <td>accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mrpc</th>\n",
       "      <td>Microsoft Research Paraphrase Corpus</td>\n",
       "      <td>Determine whether the sentences in the pair are semantically equivalent</td>\n",
       "      <td>3.7k</td>\n",
       "      <td>f1/accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stsb</th>\n",
       "      <td>Semantic Textual Similarity Benchmark</td>\n",
       "      <td>Determine similarity score for 2 sentences</td>\n",
       "      <td>7k</td>\n",
       "      <td>pearsonr/spearmanr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qqp</th>\n",
       "      <td>Quora question pair</td>\n",
       "      <td>Determine if 2 questions are the same (paraphrase)</td>\n",
       "      <td>364k</td>\n",
       "      <td>f1/accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mnli</th>\n",
       "      <td>Mulit-Genre Natural Language Inference</td>\n",
       "      <td>Predict whether the premise entails, contradicts or is neutral to the hypothesis</td>\n",
       "      <td>393k</td>\n",
       "      <td>accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qnli</th>\n",
       "      <td>Stanford Question Answering Dataset</td>\n",
       "      <td>Determine whether the context sentence containsthe answer to the question</td>\n",
       "      <td>105k</td>\n",
       "      <td>accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rte</th>\n",
       "      <td>Recognize Textual Entailment</td>\n",
       "      <td>Determine whether one sentece entails another</td>\n",
       "      <td>2.5k</td>\n",
       "      <td>accuracy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wnli</th>\n",
       "      <td>Winograd Schema Challenge</td>\n",
       "      <td>Predict if the sentence with the pronoun substituted is entailed by the original sentence</td>\n",
       "      <td>634</td>\n",
       "      <td>accuracy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#hide_input\n",
    "abreviations=[\"cola\",\"sst2\",\"mrpc\",\"stsb\",\"qqp\",\"mnli\",\"qnli\",\"rte\",\"wnli\"]\n",
    "name = [\n",
    "    \"Corpus of Linguistic Acceptability\",\n",
    "    \"Stanford Sentiment Treebank\",\n",
    "    \"Microsoft Research Paraphrase Corpus\",\n",
    "    \"Semantic Textual Similarity Benchmark\",\n",
    "    \"Quora question pair\",\n",
    "    \"Mulit-Genre Natural Language Inference\",\n",
    "    \"Stanford Question Answering Dataset\",\n",
    "    \"Recognize Textual Entailment\",\n",
    "    \"Winograd Schema Challenge\"\n",
    "]\n",
    "descriptions = [\n",
    "    \"Determine whether it is a grammatical sentence\",\n",
    "    \"Predict the sentiment of a givensentence\",\n",
    "    \"Determine whether the sentences in the pair are semantically equivalent\",\n",
    "    \"Determine similarity score for 2 sentences\",\n",
    "    \"Determine if 2 questions are the same (paraphrase)\",\n",
    "    \"Predict whether the premise entails, contradicts or is neutral to the hypothesis\",\n",
    "    \"Determine whether the context sentence containsthe answer to the question\",\n",
    "    \"Determine whether one sentece entails another\",\n",
    "    \"Predict if the sentence with the pronoun substituted is entailed by the original sentence\"\n",
    "]\n",
    "df = pd.DataFrame({'Name':name,\n",
    "                   'Task description':descriptions,\n",
    "                   'Size':['8.5k','67k','3.7k','7k','364k','393k','105k','2.5k', '634'],\n",
    "                   'Metrics':['matthews_corrcoef','accuracy','f1/accuracy','pearsonr/spearmanr',\n",
    "                              'f1/accuracy','accuracy','accuracy','accuracy','accuracy']},\n",
    "                   index=abreviations)\n",
    "display_df(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Let's define main settings for the run in one place. You can choose any model from wide variety presented in HuggingFace model hub. Some might need special treatment to work but most models of appropriate class should be plug-and-play."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "ds_name = 'glue'\n",
    "model_name = \"distilroberta-base\"\n",
    "\n",
    "max_len = 512\n",
    "bs = 32\n",
    "val_bs = bs*2\n",
    "\n",
    "n_epoch = 4\n",
    "lr = 2e-5\n",
    "opt_func = Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false",
    "id": "03T3tt0I8PA0"
   },
   "source": [
    "To make switching between datasets smooth I'll define couple of dictionaries containing per-task information. We'll need metrics, text fields to retrieve data and number of outputs for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "GLUE_TASKS = [\"cola\", \"mnli\", \"mrpc\", \"qnli\", \"qqp\", \"rte\", \"sst2\", \"stsb\", \"wnli\"]\n",
    "def validate_task():\n",
    "    assert task in GLUE_TASKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "glue_metrics = {\n",
    "    'cola':[MatthewsCorrCoef()],\n",
    "    'sst2':[accuracy],\n",
    "    'mrpc':[F1Score(), accuracy],\n",
    "    'stsb':[PearsonCorrCoef(), SpearmanCorrCoef()],\n",
    "    'qqp' :[F1Score(), accuracy],\n",
    "    'mnli':[accuracy],\n",
    "    'qnli':[accuracy],\n",
    "    'rte' :[accuracy],\n",
    "    'wnli':[accuracy],\n",
    "}\n",
    "\n",
    "glue_textfields = {\n",
    "    'cola':['sentence', None],\n",
    "    'sst2':['sentence', None],\n",
    "    'mrpc':['sentence1', 'sentence2'],\n",
    "    'stsb':['sentence1', 'sentence2'],\n",
    "    'qqp' :['question1', 'question2'],\n",
    "    'mnli':['premise', 'hypothesis'],\n",
    "    'qnli':['question', 'sentence'],\n",
    "    'rte' :['sentence1', 'sentence2'],\n",
    "    'wnli':['sentence1', 'sentence2'],\n",
    "}\n",
    "\n",
    "glue_num_labels = {'mnli':3, 'stsb':1}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "We'll be using `datasets` library for HuggingFace to get data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset glue (/root/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "task = 'mrpc'; validate_task()\n",
    "ds = load_dataset(ds_name, task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "MNLI datasets contains 2 sets for validation: matched and missmatched. The mathced set is selected here for validation when fine-tuning on MNLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3668, 408)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_ = 'validation-matched' if task=='mnli' else 'validation'\n",
    "len(ds['train']), len(ds[valid_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "nt, nv = len(ds['train']), len(ds[valid_])\n",
    "train_idx, valid_idx = L(range(nt)), L(range(nt, nt+nv))\n",
    "train_ds = concatenate_datasets([ds['train'], ds[valid_]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "One can inspect single example for the given task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idx': 0,\n",
       " 'label': 1,\n",
       " 'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n",
       " 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Here I use number of characters a proxy for length of tokenized text to speed up `dls` creation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "lens = train_ds.map(lambda s: {'len': sum([len(s[i]) for i in glue_textfields[task] if i])},\n",
    "                    remove_columns=train_ds.column_names, num_proc=2, keep_in_memory=True)\n",
    "train_lens = lens.select(train_idx)['len']\n",
    "valid_lens = lens.select(valid_idx)['len']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## DataBlock and Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "`TextGetter` is analogous to `ItemGetter` but retrieves either one or two text fields from the source (e.g. \"sentence1\" and \"sentence2\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class TextGetter(ItemTransform):\n",
    "    def __init__(self, s1='text', s2=None):\n",
    "        self.s1, self.s2 = s1, s2\n",
    "    def encodes(self, sample):\n",
    "        if self.s2 is None: return sample[self.s1]\n",
    "        else: return sample[self.s1], sample[self.s2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Transformers expect two parts of text to be concatenated with some `SEP` token inbetween. But when displaying the batch it's better to have those texts in separate columns for better readability. To make it work I define a version of `show_batch` to be dispatched on `TransTensorText` class. It will handle cases when there is single decoded text or a tuple of two texts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class TransTensorText(TensorBase): pass\n",
    "\n",
    "@typedispatch\n",
    "def show_batch(x:TransTensorText, y, samples, ctxs=None, max_n=10, trunc_at=150, **kwargs):\n",
    "    if ctxs is None: ctxs = get_empty_df(min(len(samples), max_n))\n",
    "    if isinstance(samples[0][0], tuple):\n",
    "        samples = L((*s[0], *s[1:]) for s in samples)\n",
    "        if trunc_at is not None: samples = L((s[0].truncate(trunc_at), s[1].truncate(trunc_at), *s[2:]) for s in samples)\n",
    "    if trunc_at is not None: samples = L((s[0].truncate(trunc_at),*s[1:]) for s in samples)\n",
    "    ctxs = show_batch[object](x, y, samples, max_n=max_n, ctxs=ctxs, **kwargs)\n",
    "    display_df(pd.DataFrame(ctxs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "#collapse\n",
    "def find_first(t, e):\n",
    "    for i, v in enumerate(t):\n",
    "        if v == e: return i\n",
    "        \n",
    "def split_by_sep(t, sep_tok_id):\n",
    "    idx = find_first(t, sep_tok_id)\n",
    "    return t[:idx], t[idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Tokenization of the inputs will be done by `TokBatchTransform` which wraps pre-trained HuggingFace tokenizer. The text processing is done in batches for speed-up. We want to awoid explicit python loops when possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class TokBatchTransform(Transform):\n",
    "    def __init__(self, pretrained_model_name=None, tokenizer_cls=AutoTokenizer, \n",
    "                 config=None, tokenizer=None, with_labels=False,\n",
    "                 padding=True, truncation=True, max_length=None, **kwargs):\n",
    "        if tokenizer is None:\n",
    "            tokenizer = tokenizer_cls.from_pretrained(pretrained_model_name, config=config)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.kwargs = kwargs\n",
    "        self._two_texts = False\n",
    "        store_attr()\n",
    "    \n",
    "    def encodes(self, batch):\n",
    "        # batch is a list of tuples of ({text or (text1, text2)}, {targets...})\n",
    "        if is_listy(batch[0][0]): # 1st element is tuple\n",
    "            self._two_texts = True\n",
    "            texts = ([s[0][0] for s in batch], [s[0][1] for s in batch])\n",
    "        elif is_listy(batch[0]): \n",
    "            texts = ([s[0] for s in batch],)\n",
    "\n",
    "        inps = self.tokenizer(*texts,\n",
    "                              add_special_tokens=True,\n",
    "                              padding=self.padding,\n",
    "                              truncation=self.truncation,\n",
    "                              max_length=self.max_length,\n",
    "                              return_tensors='pt',\n",
    "                              **self.kwargs)\n",
    "        # inps are batched, collate targets into batches too\n",
    "        labels = default_collate([s[1:] for s in batch])\n",
    "        if self.with_labels:\n",
    "            inps['labels'] = labels[0]\n",
    "            res = (inps, )\n",
    "        else:\n",
    "            res = (inps, ) + tuple(labels)\n",
    "        return res\n",
    "    \n",
    "    def decodes(self, x:TransTensorText):\n",
    "        if self._two_texts:\n",
    "            x1, x2 = split_by_sep(x, self.tokenizer.sep_token_id)\n",
    "            return (TitledStr(self.tokenizer.decode(x1.cpu(), skip_special_tokens=True)),\n",
    "                    TitledStr(self.tokenizer.decode(x2.cpu(), skip_special_tokens=True)))\n",
    "        return TitledStr(self.tokenizer.decode(x.cpu(), skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "The batches processed by `TokBatchTransform` contain a dictionary as the first element. For decoding it's handy to have a tensor instead. The `Undict` transform fethces `input_ids` from the batch and creates `TransTensorText` which should work with typedispatch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class Undict(Transform):\n",
    "    def decodes(self, x:dict):\n",
    "        if 'input_ids' in x: res = TransTensorText(x['input_ids'])\n",
    "        return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Now the transforms are to be combined inside a data block to be used for `dls` creation. The inputs are prebatched by `TokBatchTranform` so we don't need to use `fa_collate` for batching, so `fa_convert` is passed in as for \"create_batch\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "dls_kwargs = {\n",
    "    'before_batch': TokBatchTransform(pretrained_model_name=model_name, max_length=max_len),\n",
    "    'create_batch': fa_convert\n",
    "}\n",
    "text_block = TransformBlock(dl_type=SortedDL, dls_kwargs=dls_kwargs, batch_tfms=Undict(), )\n",
    "\n",
    "dblock = DataBlock(blocks = [text_block, CategoryBlock()],\n",
    "                   get_x=TextGetter(*glue_textfields[task]),\n",
    "                   get_y=ItemGetter('label'),\n",
    "                   splitter=IndexSplitter(valid_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.74 s, sys: 892 ms, total: 3.63 s\n",
      "Wall time: 3.66 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "dl_kwargs=[{'res':train_lens}, {'val_res':valid_lens}]\n",
    "dls = dblock.dataloaders(train_ds, bs=bs, val_bs=val_bs, dl_kwargs=dl_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Securities and Exchange Commission yesterday said companies trading on the biggest U.S. markets must win shareholder approval before granting stock options and other stock-based compensation plans to corporate executives.</td>\n",
       "      <td>Companies trading on the biggest stock markets must get shareholder approval before granting stock options and other equity compensation under rules cleared yesterday by the Securities and Exchange Commission.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The report by the Justice Department's inspector general found \" significant problems \" in the government's handling of foreigners who were jailed under blanket edicts adopted by the department after the attacks.</td>\n",
       "      <td>The Justice Department's Office of the Inspector General described \" significant problems \" in the Bush administration's actions toward the 762 foreigners held on immigration violations after the attacks.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The government said FirstEnergy Nuclear determined that a contractor had established an unprotected high-speed computer connection to its corporate network that allowed the \" Slammer \" infection to spread internally.</td>\n",
       "      <td>It said FirstEnergy determined that a contractor had established an unprotected computer connection to its corporate network that allowed the so-called ``Slammer'' worm to spread internally.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Microsoft favors setting up \" independent e-mail trust authorities to establish and maintain commercial email guidelines, certify senders who follow the guidelines, and resolve customer disputes. \"</td>\n",
       "      <td>Gates says he wants to see \" independent e-mail trust authorities \" who \" establish and maintain commercial email guidelines, certify senders who follow the guidelines, and resolve customer disputes. \"</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls.show_batch(max_n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Customised Learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Now the `xb` we get from dataloader contains a dictionary and HuggingFace transformers accept keyword argument as input. To make this work smoothly I choose to create `Learner` subclass to handle correct unrolling of the input dict.\n",
    "\n",
    "But first we need to define some utility functions. `default_splitter` is used to devide model parameters into groups:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "def default_splitter(model):\n",
    "    groups = L(model.base_model.children()) + L(m for m in list(model.children())[1:] if params(m))\n",
    "    return groups.map(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Similar to `show_batch` one have to customize `show_results`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "@typedispatch\n",
    "def show_results(x: TransTensorText, y, samples, outs, ctxs=None, max_n=10, trunc_at=150, **kwargs):\n",
    "    if ctxs is None: ctxs = get_empty_df(min(len(samples), max_n))\n",
    "    if isinstance(samples[0][0], tuple):\n",
    "        samples = L((*s[0], *s[1:]) for s in samples)\n",
    "        if trunc_at is not None: samples = L((s[0].truncate(trunc_at), s[1].truncate(trunc_at), *s[2:]) for s in samples)\n",
    "    elif trunc_at is not None: samples = L((s[0].truncate(trunc_at),*s[1:]) for s in samples)\n",
    "    ctxs = show_results[object](x, y, samples, outs, ctxs=ctxs, max_n=max_n, **kwargs)\n",
    "    display_df(pd.DataFrame(ctxs))\n",
    "    return ctxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "`TransLearner` itself doesn't do much. `_do_one_batch` method is reworked to feed the unrolled input dict to the model after filtering unexpected keys. It also takes care of some small things like adding `TransCallback` and setting `splitter` to be `default_splitter` if none is provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "@delegates(Learner.__init__)\n",
    "class TransLearner(Learner):\n",
    "    \"Learner for training transformers from HuggingFace\"\n",
    "    def __init__(self, dls, model, **kwargs):\n",
    "        splitter = kwargs.get('splitter', None)\n",
    "        if splitter is None: kwargs['splitter'] = default_splitter\n",
    "        super().__init__(dls, model, **kwargs)\n",
    "        self.model_args = set(signature(model.forward).parameters.keys())\n",
    "        self.add_cb(TransCallback())\n",
    "        self.compute_loss = True\n",
    "\n",
    "    def one_batch(self, i, b):\n",
    "        self.iter = i\n",
    "        b_on_device = tuple(to_device(e) for e in b) if self.dls.device is not None else b\n",
    "        self._split(b_on_device)\n",
    "        self._with_events(self._do_one_batch, 'batch', CancelBatchException)\n",
    "    \n",
    "    def _do_one_batch(self):\n",
    "        x = self.xb[0]\n",
    "        for k in x.keys():\n",
    "            if k not in self.model_args: del x[k]\n",
    "        self.pred = self.model(**self.x)\n",
    "        self('after_pred')\n",
    "        if len(self.yb) and self.compute_loss:\n",
    "            self.loss_grad = self.loss_func(self.pred, *self.yb)\n",
    "            self.loss = self.loss_grad.clone()\n",
    "        self('after_loss')\n",
    "        if not self.training or not len(self.yb): return\n",
    "        self('before_backward')\n",
    "        self.loss_grad.backward()\n",
    "        self._with_events(self.opt.step, 'step', CancelStepException)\n",
    "        self.opt.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "By default the model returns dictionary-like object containing `logits` and possibly other outputs as defined by model config (e.g. intermediate hidden representations). In fastai training loop we usually expect `preds` to be a tensor containing model predictions (logits). To format the preds properly we can use a callback.\n",
    "\n",
    "Notice that if `labels` key is found in the input, transformer models compute the `loss` and return it togather with output `logits`. The callback below is designed to utilise the loss returned by model instead of recomputing it using `learn.loss_func`. This is not actually used in this example but might be handy in some usecases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [],
   "source": [
    "class TransCallback(Callback):\n",
    "    \"Handles HuggingFace model outputs\"\n",
    "    def after_pred(self):\n",
    "        if 'loss' in self.pred:\n",
    "            self.learn.loss_grad = self.pred.loss\n",
    "            self.learn.loss = self.pred.loss.clone()\n",
    "            if 'labels' in self.xb[0].keys():\n",
    "                self.learn.yb = (self.xb[0]['labels'], )\n",
    "            self.learn.compute_loss = False\n",
    "        self.learn.pred = self.pred.logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Training\n",
    "\n",
    "After all the preparations the training is streightforward. Setting `num_labels` for the model and choosing apropriate metrics is automated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.layer_norm.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#hide_output\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=glue_num_labels.get(task, 2))\n",
    "metrics = glue_metrics[task]\n",
    "learn = TransLearner(dls, model, metrics=metrics, opt_func=opt_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification (Input shape: 32)\n",
       "============================================================================\n",
       "Layer (type)         Output Shape         Param #    Trainable \n",
       "============================================================================\n",
       "                     32 x 103 x 768      \n",
       "Embedding                                 38603520   True      \n",
       "Embedding                                 394752     True      \n",
       "Embedding                                 768        True      \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     True      \n",
       "Linear                                    590592     True      \n",
       "Linear                                    590592     True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     True      \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     32 x 103 x 3072     \n",
       "Linear                                    2362368    True      \n",
       "____________________________________________________________________________\n",
       "                     32 x 103 x 768      \n",
       "Linear                                    2360064    True      \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     True      \n",
       "Linear                                    590592     True      \n",
       "Linear                                    590592     True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     True      \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     32 x 103 x 3072     \n",
       "Linear                                    2362368    True      \n",
       "____________________________________________________________________________\n",
       "                     32 x 103 x 768      \n",
       "Linear                                    2360064    True      \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     True      \n",
       "Linear                                    590592     True      \n",
       "Linear                                    590592     True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     True      \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     32 x 103 x 3072     \n",
       "Linear                                    2362368    True      \n",
       "____________________________________________________________________________\n",
       "                     32 x 103 x 768      \n",
       "Linear                                    2360064    True      \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     True      \n",
       "Linear                                    590592     True      \n",
       "Linear                                    590592     True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     True      \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     32 x 103 x 3072     \n",
       "Linear                                    2362368    True      \n",
       "____________________________________________________________________________\n",
       "                     32 x 103 x 768      \n",
       "Linear                                    2360064    True      \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     True      \n",
       "Linear                                    590592     True      \n",
       "Linear                                    590592     True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     True      \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     32 x 103 x 3072     \n",
       "Linear                                    2362368    True      \n",
       "____________________________________________________________________________\n",
       "                     32 x 103 x 768      \n",
       "Linear                                    2360064    True      \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     True      \n",
       "Linear                                    590592     True      \n",
       "Linear                                    590592     True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     True      \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     32 x 103 x 3072     \n",
       "Linear                                    2362368    True      \n",
       "____________________________________________________________________________\n",
       "                     32 x 103 x 768      \n",
       "Linear                                    2360064    True      \n",
       "LayerNorm                                 1536       True      \n",
       "Dropout                                                        \n",
       "Linear                                    590592     True      \n",
       "Dropout                                                        \n",
       "____________________________________________________________________________\n",
       "                     32 x 2              \n",
       "Linear                                    1538       True      \n",
       "____________________________________________________________________________\n",
       "\n",
       "Total params: 82,119,938\n",
       "Total trainable params: 82,119,938\n",
       "Total non-trainable params: 0\n",
       "\n",
       "Optimizer used: <function Adam at 0x7fb8161b7048>\n",
       "Loss function: FlattenedLoss of CrossEntropyLoss()\n",
       "\n",
       "Callbacks:\n",
       "  - TrainEvalCallback\n",
       "  - TransCallback\n",
       "  - Recorder\n",
       "  - ProgressCallback"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collapse_output\n",
    "learn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>f1_score</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.610563</td>\n",
       "      <td>0.538350</td>\n",
       "      <td>0.819970</td>\n",
       "      <td>0.708333</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.455006</td>\n",
       "      <td>0.353764</td>\n",
       "      <td>0.889279</td>\n",
       "      <td>0.845588</td>\n",
       "      <td>00:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.320432</td>\n",
       "      <td>0.384724</td>\n",
       "      <td>0.888519</td>\n",
       "      <td>0.835784</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.238442</td>\n",
       "      <td>0.350724</td>\n",
       "      <td>0.897747</td>\n",
       "      <td>0.855392</td>\n",
       "      <td>00:20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Better model found at epoch 0 with f1_score value: 0.8199697428139183.\n",
      "Better model found at epoch 1 with f1_score value: 0.8892794376098417.\n",
      "Better model found at epoch 3 with f1_score value: 0.8977469670710572.\n"
     ]
    }
   ],
   "source": [
    "metric_to_monitor = metrics[0].name if isinstance(metrics[0], Metric) else metrics[0].__name__\n",
    "cbs = [SaveModelCallback(monitor=metric_to_monitor)]\n",
    "learn.fit_one_cycle(4, lr, cbs=cbs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "After training the model it's useful to verify  that results make sense:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_</th>\n",
       "      <th>category</th>\n",
       "      <th>category_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The delegates said raising and distributing funds has been complicated by the U.S. crackdown on jihadi charitable foundations, bank accounts of terror-related organizations and money transfers.</td>\n",
       "      <td>Bin Laden ’ s men pointed out that raising and distributing funds has been complicated by the U.S. crackdown on jihadi charitable foundations, bank accounts of terror-related organizations and money transfers.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The attack followed several days of disturbances in the city where American soldiers exchanged fire with an unknown number of attackers as civilians carried out demonstrations against the American presence.</td>\n",
       "      <td>The attack came after several days of disturbance in the city in which U.S. soldiers exchanged fire with an unknown number of attackers as civilians protested the American presence.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Massachusetts regulators and the Securities and Exchange Commission on Tuesday pressed securities fraud charges against Putnam Investments and two of its former portfolio managers for alleged improper mutual fund trading.</td>\n",
       "      <td>State and federal securities regulators filed civil charges against Putnam Investments and two portfolio managers in the ever-expanding mutual fund trading scandal.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Justice Minister Martin Cauchon and Prime Minister Jean Chrétien have both said the Liberal government will introduce legislation soon to decriminalize possession of small amounts of pot for personal use.</td>\n",
       "      <td>Justice Minister Martin Cauchon and Prime Minister Jean Chretien both have said the government will introduce legislation to decriminalize possession of small amounts of pot.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Myanmar's pro-democracy leader Aung San Suu Kyi will return home late Friday but will remain in detention after recovering from surgery at a Yangon hospital, her personal physician said.</td>\n",
       "      <td>Myanmar's pro-democracy leader Aung San Suu Kyi will be kept under house arrest following her release from a hospital where she underwent surgery, her personal physician said Friday.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>President Bush raised a record-breaking $ 49.5 million for his re-election campaign over the last three months, with contributions from 262,000 Americans, the president's campaign chairman said Tuesday.</td>\n",
       "      <td>President Bush has raised $ 83.9 million since beginning his re-election campaign in May, and has $ 70 million of that left to spend, his campaign said Tuesday.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Barry Callebaut will be able to use Brach's retail network to sell products made from its German subsidiary Stollwerck, which makes chocolate products not sold in the United States.</td>\n",
       "      <td>Barry Callebaut will be able to use Brach's retail network to sell products made from its German subsidiary Stollwerck, which makes chocolate products unknown to the American market.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>The Guru microcontroller serves four functions : hardware monitoring, overclocking management, BIOS ( Basic Input Output System ) update and a troubleshooting-assistance feature called Black Box.</td>\n",
       "      <td>The µGuru microcontroller serves four functions : hardware monitoring, overclocking management, BIOS update and a troubleshooting-assistance feature called Black Box.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Donations stemming from the Sept. 11 attacks helped push up contributions to human service organizations and large branches of the United Way by 15 percent and 28.6 percent, respectively.</td>\n",
       "      <td>Donations stemming from the Sept. 11 attacks helped push up contributions to human service organizations by 15 percent and to large branches of the United Way by 28.6 percent.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.show_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Finally we can run our model on test set to get the predictoins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "Collapsed": "false"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0094, 0.9906],\n",
       "        [0.0475, 0.9525],\n",
       "        [0.0031, 0.9969],\n",
       "        ...,\n",
       "        [0.0195, 0.9805],\n",
       "        [0.0025, 0.9975],\n",
       "        [0.0151, 0.9849]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dl = dls.test_dl(ds['test'])\n",
    "preds = learn.get_preds(dl=test_dl)\n",
    "preds[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "## Final remarks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "Collapsed": "false"
   },
   "source": [
    "Generalised versions of \"wrapper\" code used in this notebook can be found in [fasthugs](https://github.com/aikindergarten/fasthugs) library. Also you can check out some extra info on fine-tuning models on GLUE tasks in [this blogpost](https://arampacha.github.io/thoughtsamples/fastai/huggingface/transformers/2021/05/07/glue-benchmark.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
